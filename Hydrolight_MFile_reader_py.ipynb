{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hydrolight_MFile_reader_py\n",
    "# Jesse Bausell\n",
    "# September 25, 2019\n",
    "#\n",
    "# This python notebook reformats a series of Hydrolight-generated m-files (radiative transfer \n",
    "# outputs) into hdf5 files. This enables easier access to data for investigators, who can work\n",
    "# with structured variables inside the hdf5 files rather than unweildy ascii files, which are \n",
    "# difficult to utilize on a large scale. See GitHub readme for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### 1. Import libraries necessary to run the program \n",
    "import numpy as np # numpy\n",
    "import h5py # hdf5 library\n",
    "import re # regular expression library\n",
    "import os # operating system library\n",
    "import csv # comma-separated variables reader/writer library\n",
    "from tkinter import filedialog as fd # Filedialog library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### 2. Compile data from m-file into a python dictionary\n",
    "\n",
    "def ascii_MFILE_compiler(mfile_pthwy):\n",
    "    \"\"\"Compiles a m-file into a multi-layerd, nested python dictionary. For each parameters\n",
    "    Dictionary keys take on the name of the m-file column headers. If a variable changes by depth\n",
    "    as well as wavelength, these parameters are nested within the dictionary element. Actual \n",
    "    variable matrix is denoted as \"Values\" (generally displayed as wavelength x depth)    \n",
    "    Input: mfile_pthwy - m-file pathway\n",
    "    Output: HE53 - python dictionary\"\"\"\n",
    "    with open(mfile_pthwy) as raw: # open m-file\n",
    "        HE53 = {} # Create an empty dictionary\n",
    "        HE53['Header'] = [] # Create an empty list for header lines 1-4 (0-3)\n",
    "        keY = 0 # key to switch between AOPs (keY = 0) and IOPs (keY = 1)\n",
    "        # sections have two different header formats and thus require processing differences\n",
    "        for i in np.arange(4):\n",
    "            # For-loop removes the first three header lines\n",
    "            HE53['Header'].append(raw.readline()) # Add header line to list to be reformatted later\n",
    "        while 1:\n",
    "            # Cycle through m-file line by line continuously.\n",
    "            raWtitlE = raw.readline()[:-1] # Take ONE file line (this will always be the first header)\n",
    "            if raWtitlE == '':\n",
    "                # If the end of the m-file has been reached...\n",
    "                break # Break while-loop\n",
    "            else:\n",
    "                # If the end of the m-file has been reached. Entertain two different options\n",
    "                if 'component' in raWtitlE: \n",
    "                    # IOPs (absorption, scatter, backscatter, and backscatter-scatter fractions)\n",
    "                    # are reported as total values, and the \"components\" that are attributed to \n",
    "                    # pure-water, phytoplankton, CDOM, and minerals. This if-statement deals with\n",
    "                    # components and their unique header format.\n",
    "                    titlE = raWtitlE.split('\"') # Get the second header line of component section\n",
    "                    namE = titlE[3] # Isolate \"Component #\" This will later become a dictionary element \n",
    "                else:\n",
    "                    # If the m-file section is not an IOP \"Component\", but rather \"total\" IOPs or AOPs\n",
    "                    if keY == 0:\n",
    "                        # If m-file section comprises AOPs (key = 0)\n",
    "                        # Split first header title into \"-separated sections (line below)\n",
    "                        titlE = raWtitlE.split('\"') \n",
    "                        raw.readline() # skip second header title (blank and useless)\n",
    "                        namE = titlE[1] # locate varible name  first title header. Assign variable\n",
    "                        uniT = titlE[3] # locate units\n",
    "                        diM = np.asarray(titlE[4].split(),dtype=int) # Find x & y dimensions of AOP \n",
    "                        # matrix. These will be used later on to read in the data.\n",
    "                    else:\n",
    "                        # If the m-file section comprises \"Total IOPs\"\n",
    "                        titlE = linE.split() # split the first header line by empty space\n",
    "                        namE = titlE[0] # locate varible name first title header. Assign variable\n",
    "                        units = '1/m' # Assign units. All the same for IOPs (except bb/b fraction)\n",
    "                        diM = np.asarray([titlE[-2],titlE[-1]],dtype=int) # Find x & y dimensions of AOP \n",
    "                        # matrix. These will be used later on to read in the data.\n",
    "                # Select third header line. This contains data columns for m-file section (see below)\n",
    "                # first, eliminate quotation marks replace \"in air\" with -1 to quantify depth above water\n",
    "                fielDS = raw.readline()[:-1].replace('\"',' ').replace(\"in air\",\"-1\") # see annotation above\n",
    "                par_IND = fielDS.find('(') # cut out all parentheses in third header line\n",
    "                fielDS = fielDS[:par_IND].split() # split third header line by empty spaces to generate column headers\n",
    "                HE53[namE] = {} # Create an empty dictionary with name of top header. Nest it in original dictionary\n",
    "                HE53[namE]['units'] = uniT # Create \"units\" element within nested dictionary\n",
    "                DATA = np.zeros(diM)*np.nan # Create nan matrix with dimensions of m-file data\n",
    "                for i in np.arange(diM[0]):\n",
    "                    # for-loop cycles through each line of data, converts it from a string into a\n",
    "                    # numpy array, and adds it onto DATA (nan matrix).\n",
    "                    # First, take a line (linE) of numerical data. Strip away quotations, \"in air\",\n",
    "                    # and end-of-line character (\\n)\n",
    "                    linE = raw.readline().replace('\"',' ').replace(\"in air\",\"-1\").replace('\\n','')\n",
    "                    try:\n",
    "                        # Attempt to convert string into a numpy array and insert it into DATA\n",
    "                        DATA[i,:] = np.asarray(linE.split(),dtype=np.float32)\n",
    "                    except:\n",
    "                        # If an error message is generated, it means that for-loop has accidentally\n",
    "                        # reached the next header. This is prone to happen in the IOP data sections \n",
    "                        # of the m-file because the number of rows is OVER REPORTED. linE is saved and \n",
    "                        # converted into the first header of the next section of data.\n",
    "                        DATA = DATA[:i,:] # Index the remaining nan rows out of the data matrix\n",
    "                        keY=+1 # Increase switch to one in order to start reading in IOP data\n",
    "                        break # BREAK FOR-LOOP!\n",
    "                HE53[namE][fielDS[0]] = DATA[:,0] # Create first dictionary element within newly created nested for-loop. \n",
    "                fielDS.pop(0) # Remove the name of the first dictionary element from column headers\n",
    "                DATA = DATA[:,1:] # Remove the first column from the data matrix (corresponding to dictionary element)\n",
    "                try:\n",
    "                    # Determine whether the column headers are actually water column depths. \n",
    "                    HE53[namE]['Depth'] = np.asarray(fielDS,dtype=np.float32) # If fields are depths, assign them to a dictionary element\n",
    "                    HE53[namE]['Values'] = DATA # Assign data matrix to a field called \"Values\" (wavelength x depth)\n",
    "                except:\n",
    "                    # If the column headers are NOT depths, and are comprised of words....\n",
    "                    for i, j in enumerate(fielDS):\n",
    "                        # Make each column header into an element name in the nested dictionary\n",
    "                        HE53[namE][j] = DATA[:,i] # Match the column header with corresponding matrix column \n",
    "        return(HE53) # Return the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### 3. Compile data from m-file into a python dictionary\n",
    "\n",
    "def hdf5_fileWRITER(filE_NAME,HE53_dict):\n",
    "    \"\"\"Takes the python dictionary that was generated by ascii_MFILE_compiler and writes them\n",
    "    into a hdf5 (.h5) file. Data within hdf5 file is formatted the same as the aforementioned \n",
    "    python dictionary. User should note however that \"bb/b ratio\" will be changed to \"bb fraction\"\n",
    "    in all headers.\n",
    "    Inputs: \n",
    "        filE_NAME - name of future hdf5 file that will contain dictionary data\n",
    "        HE53_dict - dictionary formatted by ascii_MFILE_compiler\n",
    "    Outputs:\n",
    "        filE_NAME.h5 - hdf5 file containing python dictionary data\"\"\"\n",
    "    with h5py.File(filE_NAME + '.h5','w') as hf: # Create an open hdf5 file for writing.\n",
    "        for k in HE53_dict:\n",
    "            # for-loop disects the m-file dictionary and writes data and dictionary elements\n",
    "            # into a hdf5 file.\n",
    "            if k != 'Header':\n",
    "                # For all dictionary elements EXCEPT for \"Header\", which contains the first four\n",
    "                # lines of the m-file...\n",
    "                if '/' in k or '(' in k:\n",
    "                    # If a header denotes a m-file IOP component...\n",
    "                    k_nuggets = k.split() # split string by white spaces \n",
    "                    if k_nuggets[0] == 'bb/b': \n",
    "                        # if dictionary key contains \"bb/b\"...\n",
    "                        k_nuggets[0] = 'bb fraction' # change \"bb/b\" to \"bb fraction\"   \n",
    "                    name = k_nuggets[0] + ' ' + k_nuggets[-2] + k_nuggets[-1] # add \"component #\" \n",
    "                else:\n",
    "                    # If a header does not denote a m-file IOP component \n",
    "                    # (e.g. AOP or total IOP variable)\n",
    "                    name = k # Use the original name of the dictionary key\n",
    "                # create a \"python dictionary\" in recently-created hdf5 file...\n",
    "                hf.create_group(name) # Create a key/element in hdf5 file based on nested python dictionary\n",
    "                for l in HE53_dict[k]:\n",
    "                    # Within the python dictionary, take all elements (keys and data) and incorporate them \n",
    "                    # into hdf5 file\n",
    "                    hf[name][l] = HE53_dict[k][l] # Create new nested element with data in hdf5 file\n",
    "            else:\n",
    "                # When program encounters the Header element...\n",
    "                hf['Meta Data'] = HE53_dict['Header'][0] # Insert first line of 4-line header into hdf5 file\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### 4. Define a program that can create a new folder for storing data files on computer.\n",
    "\n",
    "def createFolder(directory):\n",
    "    \"\"\" createFolder searches for a dirctory specified by the user. If there is none, it creates one\"\"\"\n",
    "    try:\n",
    "        if not os.path.exists(directory): # If the folder doesn't exist\n",
    "            os.makedirs(directory) # Create a folder\n",
    "    except OSError: # If there is an error other than a non-existant folder\n",
    "        print ('Error: Creating directory. ' +  directory) # report error and shut down createFolder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def selecT_HE53_vars(HE53,mfile_name):\n",
    "    \"\"\"Select distinct variables from python dictionary for publication in csv file.\n",
    "    Inputs:\n",
    "        HE53 - python dictionary with data extracted from m-file\n",
    "        mfile_name - original name of m-file\n",
    "    Outputs: \n",
    "        ITR - iteration, or series number of m-file/hdf5 file (LogNorm_Draw_Hydrolight creates numerically ordered files)\n",
    "        Chl - input chlorophyll\n",
    "        CDOM - input Gelbstoff absorption (440 nm)\n",
    "        TSS - input total suspended sediment/total suspended matter\n",
    "        kd320 - diffuse attenuation coefficient 320 nm\n",
    "        kd780 - diffuse attenuation coefficient 780 nm\n",
    "        Kd412 - diffuse attenuation coefficient 412 nm\n",
    "        Kd667 - diffuse attenuation coefficient 667 nm\n",
    "        aph443 - phytoplankton absorption 443 nm\n",
    "        ag443 - Galbstoff absorption 443 nm\n",
    "        amin443 - mineral absorption 443 nm\n",
    "        bb_ph667 - phytoplankton backscattering 667 nm\n",
    "        bb_min667 - mineral backscattering 667 nm\n",
    "        bb_phFrac - phytoplankton backscatter/scatter fraction \n",
    "        bb_minFrac -mineral backscatter/scatter fraction\"\"\"\n",
    "    # Determine relative iteration of the m-file using header     \n",
    "    itr_IND = mfile_name.find('itr_')+4\n",
    "    txt_IND = mfile_name.find('.txt')\n",
    "    ITR = int(mfile_name[itr_IND:txt_IND])\n",
    "    # Find Kd320 and Kd780\n",
    "    kd320 = HE53['Kd']['Values'][0,0]\n",
    "    kd780 = HE53['Kd']['Values'][-1,0]\n",
    "    # Find Kd412 and Kd670\n",
    "    Kd412 = HE53['Kd']['Values'][2,0]\n",
    "    Kd667 = HE53['Kd']['Values'][-2,0]\n",
    "    # Find CDOM, phytoplankton and mineral absorption at 443 nm\n",
    "    aph443 = HE53['a (1/m) for component  2']['Values'][3,0]\n",
    "    ag443 = HE53['a (1/m) for component  3']['Values'][3,0]\n",
    "    amin443 = HE53['a (1/m) for component  4']['Values'][3,0]\n",
    "    # Find phytoplankton and mineral backscattering at 667 nm\n",
    "    bb_ph667 = HE53['bb (1/m) for component  2']['Values'][-2,0]\n",
    "    bb_min667 = HE53['bb (1/m) for component  4']['Values'][-2,0]\n",
    "    # Find Chl, CDOM (ag440) and TSS based on the first Header line in the m-file\n",
    "    titlE = HE53[\"Header\"][0].split(',') \n",
    "    Chl_IND = titlE[1].find('=')+1\n",
    "    Chl = float(titlE[1][Chl_IND:])\n",
    "    CDOM_IND = titlE[2].find('=')+1\n",
    "    CDOM = float(titlE[2][CDOM_IND:])\n",
    "    TSS_IND = titlE[3].find('=')+1\n",
    "    TSS = float(titlE[3][TSS_IND:])    \n",
    "    # Find bb_phFrac and bb_minFrac\n",
    "    bb_phFrac = HE53['bb/b ratio for component  2']['Values'][0,0]\n",
    "    bb_minFrac = HE53['bb/b ratio for component  4']['Values'][0,0]\n",
    "    return(ITR,Chl,CDOM,TSS,kd320,kd780,Kd412,Kd667,aph443,ag443,amin443,bb_ph667,bb_min667,bb_phFrac,bb_minFrac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 6. This cell is where MFile_reader_py is executed from. The code \n",
    "## 6a. Create the necessary file pathways and variables to compile m-files\n",
    "template_dir = fd.askdirectory() # Select directory containing m-files\n",
    "if '/' in template_dir:\n",
    "    # If files are on a mac\n",
    "    dasH = '/' # Folder separator for directory pathway\n",
    "else:\n",
    "    # If files are on a pc\n",
    "    dasH = '\\\\' # Folder separator for directory pathway\n",
    "mfile_pthwy = template_dir+dasH # Add a \"/\" or \"\\\\\" onto the end of the folder\n",
    "dash_IND = [w.start() for w in re.finditer(dasH, mfile_pthwy)] # locate file separators\n",
    "# Create a string indicating patyway of hdf5 files (below)\n",
    "hdf5_file_pthwy = template_dir[:dash_IND[-2]+1] + 'hdf5' + dasH # See line above\n",
    "csv_file_pthwy = template_dir[:dash_IND[-2]+1] + dasH # csv file pathway\n",
    "createFolder(hdf5_file_pthwy) # Create a pathway on the computer for hdf5 files\n",
    "matLISt = os.listdir(mfile_pthwy) # list all files in m-file directory\n",
    "csv_DATA_MATRIX = np.zeros([len(matLISt),15])*np.nan # Create a data matrix to place \n",
    "mFILE_LIST = [] # Create an empty list for m-files to keep track of their original order\n",
    "# variables earmarked for csv file\n",
    "## 6b. Convert m-files into hdf5 format and extract necessary data into numpy matrix\n",
    "for i,mFILE in enumerate(matLISt):\n",
    "    # This for-loop cyles through m-files in user-selected folder. Data in each m-file (ascii)\n",
    "    # is re-formatted into a hdf5 file (.h5) which is placed into a folder named \"hdf5\" \n",
    "    # adjacent to the user-selected m-file folder.\n",
    "    if mFILE[0] == 'M' and '.txt' in mFILE:\n",
    "        # Make sure that the file is indeed an m-file (ascii)\n",
    "        # Compile information from m-file into python dictionary (line below)\n",
    "        HE53 = ascii_MFILE_compiler(mfile_pthwy + mFILE) # Compiles m-file data into dictionary\n",
    "        # extract data from dictionary and place it into numpy matrix (below)\n",
    "        csv_DATA_MATRIX[i,:] = np.asarray(selecT_HE53_vars(HE53,mFILE),dtype=float) \n",
    "        t_IND = mFILE.find('.txt') # Find the index \".txt\" part of ascii file\n",
    "        filE_NAME_hdf5 = mFILE[:t_IND] # Cut off \".txt\" and leave only the root of m-file name\n",
    "        # Format dictionary into hdf5 file using root of m-file name (below)\n",
    "        mFILE_LIST.append(mFILE) # Add m-file name to the list of m-files\n",
    "        hdf5_fileWRITER(hdf5_file_pthwy+filE_NAME_hdf5,HE53) # Create hdf5 file\n",
    "## 6c. Write numpy matrix into csv file\n",
    "# 6c1. Prepare the numpy matrix\n",
    "nan_IND = ~np.isnan(csv_DATA_MATRIX[:,0]) # Find rows that DO NOT contain nan values\n",
    "csv_DATA_MATRIX = csv_DATA_MATRIX[nan_IND,:] # Exclude all matrix rows with nan values\n",
    "# Determine bb/b fractions for phytoplankton and minerals (last two columsn of csv_DATA_MATRIX)\n",
    "bb_ph = str(np.round(csv_DATA_MATRIX[0,-2],decimals=3)) # bb/b phytoplankton (string)\n",
    "bb_min = str(np.round(csv_DATA_MATRIX[0,-1],decimals=3))# bb/b minerals (string)\n",
    "csv_DATA_MATRIX = csv_DATA_MATRIX[:,:-2] # Remove the last two columns from the data matrix\n",
    "csv_DATA_MATRIX[:,0] = csv_DATA_MATRIX[:,0] - min(csv_DATA_MATRIX[:,0]) #shift indices to 0-999\n",
    "# 6c2. Write csv file and place it adjacent to m-file and hdf5 folders\n",
    "filE_NAME_csv = 'Ch2_HE53' + 'bb_ph' + bb_ph + 'bb_min' + bb_min + '.csv' # csv file name\n",
    "# List column headers (below...)\n",
    "HE53_header = ['m-file','Index','Chlorophyll (ug/L)','CDOM (/m)', 'TSM (g/m^3)','kd320','kd780',\n",
    "               'Kd412','Kd667','aph443','ag443','amin443','bb_ph667','bb_min667'] \n",
    "with open(csv_file_pthwy+filE_NAME_csv, 'w', newline='') as csvfile: # Write new csv file\n",
    "    # Format csv file (below)\n",
    "    spamwriter = csv.writer(csvfile, delimiter=',',quotechar='|', quoting=csv.QUOTE_MINIMAL) #gives a file identifier to the csv file\n",
    "    spamwriter.writerow(HE53_header) # Add column headers with units\n",
    "    for i, linE in enumerate(csv_DATA_MATRIX): \n",
    "        # For-loop takes rows of data and writes them into csv file\n",
    "        linE = list(linE) # Take a slice of the numpy matrix and make it into a list\n",
    "        linE.insert(0,mFILE_LIST[i]) # Insert m-file name at the top of the list\n",
    "        spamwriter.writerow(linE) # Write the list into csv file\n",
    "    \n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
